# -*- coding: utf-8 -*-
"""41_CS4501_RandomForestRegressorModel_Leitrim.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w7jIeUMka5AGt-2-Rr3np2txJl7TNjMu
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext autoreload
# %autoreload 2
# %matplotlib inline

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

import os

from sklearn.tree import plot_tree

from sklearn.preprocessing import LabelEncoder

from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import DecisionTreeRegressor

from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

from sklearn.impute import SimpleImputer

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder

if 'google.colab' in str(get_ipython()):
  from google.colab import drive
  drive.mount("/content/drive", force_remount=True)
  base_dir = "./drive/My Drive/Colab Notebooks/" # You may need to change this, depending on where your notebooks are on Google Drive
else:
  base_dir = "/content/drive/My Drive/Colab Notebooks/" # You may need to change this, depending on where your datasets folder is
dataset_dir = os.path.join(base_dir, "Datasets/dataset_ber5_leitrim.csv")  # Assuming the file is a CSV

print(os.listdir(base_dir + "Datasets/"))  # This will list all files in the Datasets directory

# Load the dataset
print(dataset_dir)
df = pd.read_csv(dataset_dir)

# Shuffle the dataset
df = df.sample(frac=1, random_state=2)
df.reset_index(drop=True, inplace=True)

"""<h1>Preprocess the data</h1>"""

df.shape

df.columns

df.dtypes

# Examining the columns, their datatypes and whether there are nulls
df.info()

# Set option to display all columns
pd.set_option('display.max_columns', None)

# Look at the first 20 rows
df.head(20)

# Summary statistics
df.describe(include="all")

# Define the Energy Rating categories and their corresponding colors
energy_rating_categories = ['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3', 'D1', 'D2', 'E1', 'E2', 'F', 'G']
colors = {
    'A1': 'darkgreen', 'A2': 'darkgreen', 'A3': 'darkgreen',
    'B1': 'green', 'B2': 'green', 'B3': 'green',
    'C1': 'yellow', 'C2': 'yellow', 'C3': 'yellow',
    'D1': (1.0, 0.75, 0.0),  # Amber, using normalized RGB values
    'D2': (1.0, 0.75, 0.0),  # Amber
    'E1': 'orange', 'E2': 'orange',
    'F': 'darkorange', 'G': 'red'
}

# Count the number of buildings in each Energy Rating category
category_counts = df['EnergyRating'].value_counts().reindex(energy_rating_categories, fill_value=0)

# Create the plot
plt.figure(figsize=(10, 6))
bars = plt.bar(category_counts.index, category_counts.values, color=[colors[cat] for cat in category_counts.index])
plt.xlabel('Energy Rating')
plt.ylabel('Number of Buildings')
plt.title('Number of Buildings by Energy Rating Category in Leitrim')

# Add counts above the bars
for bar in bars:
    height = bar.get_height()
    plt.annotate('{}'.format(height),
                 xy=(bar.get_x() + bar.get_width() / 2, height),
                 xytext=(0, 3),  # 3 points vertical offset
                 textcoords="offset points",
                 ha='center', va='bottom')

# Show the plot
plt.show()

# Calculate and print the number and percentage of properties in E1, E2, F, and G categories
total_properties = len(df)
high_energy_consumption = category_counts['E1'] + category_counts['E2'] + category_counts['F'] + category_counts['G']
print(f'Number of properties in E1, E2, F, and G categories: {high_energy_consumption}')
high_energy_percentage = (high_energy_consumption / total_properties) * 100
print(f'Percentage of properties in E1, E2, F, and G categories: {high_energy_percentage:.2f}%')

# Check for missing values
df.isnull().sum()

# Make a copy of the dataset
copy_df = df.copy()

# Reset the index
copy_df.reset_index(drop=True, inplace=True)

copy_df.shape

# List of U-value, Area and Efficiency columns in the dataset
list_columns = ["UValueWall", "UValueRoof", "UValueFloor", "UValueWindow", "UvalueDoor", "WallArea", "RoofArea",
                "FloorArea", "WindowArea", "DoorArea", "HSMainSystemEfficiency", "HSSupplSystemEff", "WHMainSystemEff", "GroundFloorUValue"]

# Calculate the number of rows needed for subplots (with 3 plots per row)
num_plots = len(list_columns)
num_rows = num_plots // 3 + (num_plots % 3 > 0)

# Create a figure and a grid of subplots
fig, axes = plt.subplots(num_rows, 3, figsize=(20, 6*num_rows))

# Flatten the axes array for easy iteration, in case of multiple rows
axes = axes.flatten()

for i, column in enumerate(list_columns):
    # Plotting the density plot for the current U-value column on subplot i
    sns.kdeplot(data=copy_df, x=column, fill=True, common_norm=False, alpha=0.5, ax=axes[i])

    # Calculating the mean for the current U-value column
    mean_value = copy_df[column].mean()

    # Plotting a vertical line for the mean value on subplot i
    axes[i].axvline(mean_value, color='r', linestyle='--')

    # Annotating the mean value on the subplot i
    axes[i].text(mean_value, 0, f"Mean: {mean_value:.2f}", color="red", ha="right", va="bottom")

    # Setting the title, and the x and y labels for subplot i
    axes[i].set_title(f"Density Plot for {column}")
    axes[i].set_xlabel(f"{column}")
    axes[i].set_ylabel("Density")

# Adjust layout to prevent overlap
plt.tight_layout()

# Hide any unused subplots if the number of plots is not a multiple of 3
for j in range(i+1, num_rows * 3):
    fig.delaxes(axes[j])

plt.show()

#'features' list contains the names of all columns in a dataset related to criminal records and rehabilitation
features = ["PropertyID", "CountyName", "DwellingTypeDescr", "Year_of_Construction", "TypeofRating",
            "EnergyRating", "BerRating", "TotalFloorArea", "UValueWall", "UValueRoof", "UValueFloor",
            "UValueWindow", "UvalueDoor", "WallArea", "RoofArea", "FloorArea", "WindowArea", "DoorArea",
            "NoStoreys", "CO2Rating", "MainSpaceHeatingFuel", "MainWaterHeatingFuel", "HSMainSystemEfficiency",
            "MultiDwellingMPRN", "HSSupplSystemEff", "WHMainSystemEff", "GroundFloorUValue", "SolarHotWaterHeating",
            "InsulationType", "InsulationThickness", "GroundFloorArea", "GroundFloorHeight", "FirstFloorArea",
            "FirstFloorHeight", "SecondFloorArea", "SecondFloorHeight", "ThirdFloorArea", "ThirdFloorHeight",
            "RoomInRoofArea", "PurposeOfRating", "DateOfAssessment"]

# 'numeric_features' list contains names of columns with numerical data
numeric_features = ["PropertyID", "Year_of_Construction", "TotalFloorArea", "UValueWall",
                    "UValueRoof", "UValueFloor", "UValueWindow", "UvalueDoor", "WallArea",
                    "RoofArea", "FloorArea", "WindowArea", "DoorArea", "NoStoreys",
                    "HSMainSystemEfficiency", "HSSupplSystemEff", "WHMainSystemEff", "GroundFloorUValue",
                    "InsulationThickness", "GroundFloorArea", "GroundFloorHeight", "FirstFloorArea",
                    "FirstFloorHeight", "SecondFloorArea", "SecondFloorHeight", "ThirdFloorArea",
                    "ThirdFloorHeight", "RoomInRoofArea"] # BerRating and CO2Rating has been removed from numeric_features

# 'nominal_features' list contains names of columns with objects/strings
nominal_features = ["CountyName", "DwellingTypeDescr", "TypeofRating", "MainSpaceHeatingFuel",
                    "MainWaterHeatingFuel", "MultiDwellingMPRN", "SolarHotWaterHeating",
                    "InsulationType", "PurposeOfRating", "DateOfAssessment"] #EnergyRating has been removed from nominal features


streamlined_numeric_features = ["PropertyID", "Year_of_Construction", "TotalFloorArea", "UValueWall",
                    "UValueRoof", "UValueFloor", "UValueWindow", "UvalueDoor", "NoStoreys",
                    "HSMainSystemEfficiency", "HSSupplSystemEff", "WHMainSystemEff", "GroundFloorUValue",
                    "InsulationThickness"] # BerRating and CO2Rating has been removed from streamlined_numeric_features

# 'nominal_features' list contains names of columns with objects/strings
streamlined_nominal_features = ["CountyName", "DwellingTypeDescr", "TypeofRating", "SolarHotWaterHeating",
                    "InsulationType", "DateOfAssessment"] #EnergyRating has been removed from streamlined_nominal features

# Verify the existence of the columns in your DataFrame
assert set(streamlined_numeric_features).issubset(copy_df.columns), "Some numeric features are missing in the DataFrame."
assert set(streamlined_nominal_features).issubset(copy_df.columns), "Some nominal features are missing in the DataFrame."

# Preprocess the data
preprocessor = ColumnTransformer([
    ("nom", Pipeline([
        ("imputer", SimpleImputer(missing_values=np.nan, strategy="most_frequent")),
        ("binarizer", OneHotEncoder(handle_unknown="ignore"))
    ]), streamlined_nominal_features),
    ("num", StandardScaler(), streamlined_numeric_features)
], remainder="drop")  # Drop other columns not specified in 'numeric_features' or 'nominal_features'

# Extract target variable before any modification
y = copy_df["BerRating"].values.ravel()

# Now, use the preprocessor to fit and transform the training data
X = copy_df[streamlined_nominal_features + streamlined_numeric_features]  # Include only the columns that are being preprocessed

# Before splitting, confirm columns presence
print(copy_df.columns)

"""**Hold-out method**"""

# Split the dataset into training (60%), validation (20%), and test (20%) sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.6, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, train_size=0.5, random_state=42)

# Before preprocessing, again confirm the presence of necessary columns
print(X_train.columns)

# Fit the preprocessor and transform the data
X_train_preprocessed = preprocessor.fit_transform(X_train)
X_val_preprocessed = preprocessor.transform(X_val)
X_test_preprocessed = preprocessor.transform(X_test)

# Initialize the model
model = RandomForestRegressor(n_estimators=100, random_state=42)

# Fit the model
model.fit(X_train_preprocessed, y_train)

# After fitting the model, check feature importance
feature_importances = model.feature_importances_

# Get feature names from the preprocessor
# For one-hot encoded features, use get_feature_names_out from OneHotEncoder
feature_names = preprocessor.named_transformers_['nom']['binarizer'].get_feature_names_out(streamlined_nominal_features)
feature_names = np.concatenate([feature_names, streamlined_numeric_features])  # combine with numeric features

# Map feature importances to feature names
importance_dict = dict(zip(feature_names, feature_importances))
importance_dict_sorted = dict(sorted(importance_dict.items(), key=lambda item: item[1], reverse=True))

# Print the sorted feature importance
#for feature, importance in importance_dict_sorted.items():
    #print(f"{feature}: {importance}")

# Number of top features to display
top_n = 15  # Cange this number based on how many top features to display

# Get feature importances
importances = model.feature_importances_

# Sort feature importances in descending order and get top N
indices = np.argsort(importances)[-top_n:][::-1]

# Rearrange feature names so they match the sorted feature importances, but only for top N
top_names = [feature_names[i] for i in indices]

# Create plot
plt.figure(figsize=(10, top_n / 2))  # Adjust the figure size appropriately

# Create plot title
plt.title("Top {} Feature Importance".format(top_n))

# Add horizontal bars for top N features
plt.barh(range(top_n), importances[indices], color='b', align='center')

# Add feature names as y-axis labels
plt.yticks(range(top_n), top_names)

# Invert the y-axis to have the highest importance feature on top
plt.gca().invert_yaxis()

# Add axes labels
plt.xlabel('Importance')
plt.ylabel('Features')

# Adjust layout for better display
plt.tight_layout()

# Show plot
plt.show()

"""Training"""

# Predicting on Training set
y_train_pred = model.predict(X_train_preprocessed)

# Calculate and print RMSE for the training set
print("Training RMSE:", np.sqrt(mean_squared_error(y_train, y_train_pred)))

# Calculate and print R^2 for training set
print("Training R^2:", r2_score(y_train, y_train_pred))

# Visualization of Prediction Accuracy for Training Set
plt.figure(figsize=(14, 7))

plt.subplot(1, 2, 1)
sns.scatterplot(x=y_train, y=y_train_pred, alpha=0.5)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)
plt.title('Training Set: Actual vs. Predicted')
plt.xlabel('Actual Energy Ratings')
plt.ylabel('Predicted Energy Ratings')

# Create a DataFrame from the actual and predicted BerRating values
energy_ratings_comparison = pd.DataFrame({
    "Actual BerRating": y_train,  # Ensure this is BerRating, not EnergyRating
    "Predicted BerRating": y_train_pred  # Predicted BerRating before improvements
})

# Extract property IDs using the indices from the train set
train_indices = X_train.index
energy_ratings_comparison["PropertyID"] = copy_df.loc[train_indices, "PropertyID"].values

print(energy_ratings_comparison.head())

# Save this DataFrame to a CSV file
#energy_ratings_comparison.to_csv('training_set_energy_ratings_comparison.csv', index=False)

# Evaluate the model
y_val_pred = model.predict(X_val_preprocessed)

# Calculate and print RMSE for validation set
print("Validation RMSE:", np.sqrt(mean_squared_error(y_val, y_val_pred)))

# Calculate and print R^2 for validation set
print("Validation R^2:", r2_score(y_val, y_val_pred))

# Visualization of Prediction Accuracy for Validation Set
plt.figure(figsize=(14, 7))

plt.subplot(1, 2, 1)
sns.scatterplot(x=y_val, y=y_val_pred, alpha=0.5)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)
plt.title('Validation Set: Actual vs. Predicted')
plt.xlabel('Actual Energy Ratings')

# Define the path where you want to save the model
model_directory = '/content/drive/My Drive/Colab Notebooks/Models'

# Print the directory path
print("Model directory path:", model_directory)

# Define the full path for the model file
model_file_path = '/content/drive/My Drive/Colab Notebooks/Models/random_forest_regressor_model2.joblib'

# Save the model
joblib.dump(model, model_file_path)
print(f"Model saved successfully at {model_file_path}")

"""Testing"""

# Final evaluation on the test set (only after finalizing the model)
y_test_pred = model.predict(X_test_preprocessed)
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
test_r2 = r2_score(y_test, y_test_pred)
print("Test RMSE:", test_rmse)
print("Test R^2:", test_r2)

# Visualization of Prediction Accuracy for Test Set
plt.figure(figsize=(14, 7))

plt.subplot(1, 2, 1)
sns.scatterplot(x=y_test, y=y_test_pred, alpha=0.5)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)
plt.title('Test Set: Actual vs. Predicted')
plt.xlabel('Actual Energy Ratings')

# Save the final model and scaler
joblib.dump(model, '/content/drive/My Drive/Colab Notebooks/Models/streamlined_random_forest_regressor_model2.joblib')
joblib.dump(preprocessor, '/content/drive/My Drive/Colab Notebooks/Models/preprocessor2.joblib')